{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWqQnR1c6kv8"
      },
      "outputs": [],
      "source": [
        "#Roll no:DS5B-2125\n",
        "#This is a classification problem need to be solve using logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqzJlGMKFVpM",
        "outputId": "c45aea6b-3b14-4ef5-a520-e3d7229dfcee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 47 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 38.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=0aadd585668286b4d4248e7569f1046bd796d5f494055601aa4d922d0c68a88d\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "session=SparkSession.builder.appName(\"HRComma\").master(\"local[2]\").getOrCreate()"
      ],
      "metadata": {
        "id": "VRpZJym-F0Ly"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=session.read.csv(\"/content/HR comma (1).csv\",header=True, inferSchema=True) #roll no:-2131"
      ],
      "metadata": {
        "id": "FLeQ37tg1IIo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5yDdRrb7yq9",
        "outputId": "d75f5aa3-1a3a-4513-a3df-425b2d8ed9f0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['satisfaction_level',\n",
              " 'last_evaluation',\n",
              " 'number_project',\n",
              " 'average_montly_hours',\n",
              " 'time_spend_company',\n",
              " 'Work_accident',\n",
              " 'left',\n",
              " 'promotion_last_5years',\n",
              " 'sales',\n",
              " 'salary']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyewTlH6HRh1",
        "outputId": "d673c6a6-8237-4a60-b930-9aaa1a482599"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+---------------+--------------+--------------------+------------------+-------------+----+---------------------+-----+------+\n",
            "|satisfaction_level|last_evaluation|number_project|average_montly_hours|time_spend_company|Work_accident|left|promotion_last_5years|sales|salary|\n",
            "+------------------+---------------+--------------+--------------------+------------------+-------------+----+---------------------+-----+------+\n",
            "|              0.38|           0.53|             2|                 157|                 3|            0|   1|                    0|sales|   low|\n",
            "|               0.8|           0.86|             5|                 262|                 6|            0|   1|                    0|sales|medium|\n",
            "|              0.11|           0.88|             7|                 272|                 4|            0|   1|                    0|sales|medium|\n",
            "+------------------+---------------+--------------+--------------------+------------------+-------------+----+---------------------+-----+------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler,StringIndexer\n",
        "str_idx=StringIndexer(inputCols=[\"sales\",\"salary\"],outputCols=[\"newsales\",\"newsalary\"])\n",
        "#this will convert input col to output col\n"
      ],
      "metadata": {
        "id": "ANFWNonXJq11"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Vector assembler is used to merge different cols into 1 col and onlybuses numeric values\n",
        "#for making different independent variables into 1 independent variable\n",
        "#henre left being dependent variable can't be used\n",
        "vec_ass=VectorAssembler(inputCols=[\"satisfaction_level\",\"number_project\",\"average_montly_hours\",\"time_spend_company\",\"Work_accident\",\"promotion_last_5years\",\"newsales\",\"newsalary\"],outputCol=\"all_features\")"
      ],
      "metadata": {
        "id": "slyrQzNRL9oh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a model\n",
        "#all supervised machine learning model take two arguments: featurescol andlabelcol\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "lr=LogisticRegression(featuresCol=\"all_features\",labelCol=\"left\")   #roll no:-2131"
      ],
      "metadata": {
        "id": "pMA1TipzNz_O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "mypipeline=Pipeline(stages=[str_idx,vec_ass,lr])"
      ],
      "metadata": {
        "id": "r59PKwiEOX0M"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dividing the datasets\n",
        "training,test=data.randomSplit([0.71,0.29])"
      ],
      "metadata": {
        "id": "kL1V1T5pPB6G"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Execute the functions\n",
        "#training the model\n",
        "lrmodel=mypipeline.fit(training)"
      ],
      "metadata": {
        "id": "bcd1mQsh6Cmo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction\n",
        "results=lrmodel.transform(test)\n",
        "results.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxdniKQEP34R",
        "outputId": "30b58a5a-6300-435f-c426-7631bd72b74d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+---------------+--------------+--------------------+------------------+-------------+----+---------------------+-----------+------+--------+---------+--------------------+--------------------+--------------------+----------+\n",
            "|satisfaction_level|last_evaluation|number_project|average_montly_hours|time_spend_company|Work_accident|left|promotion_last_5years|      sales|salary|newsales|newsalary|        all_features|       rawPrediction|         probability|prediction|\n",
            "+------------------+---------------+--------------+--------------------+------------------+-------------+----+---------------------+-----------+------+--------+---------+--------------------+--------------------+--------------------+----------+\n",
            "|              0.09|           0.77|             6|                 244|                 4|            0|   1|                    0|product_mng|   low|     4.0|      0.0|[0.09,6.0,244.0,4...|[-0.9166097349758...|[0.28564918749098...|       1.0|\n",
            "|              0.09|           0.78|             6|                 254|                 4|            0|   1|                    0|    support|   low|     2.0|      0.0|[0.09,6.0,254.0,4...|[-1.0141132719151...|[0.26617564876634...|       1.0|\n",
            "|              0.09|           0.78|             6|                 254|                 4|            0|   1|                    0|    support|   low|     2.0|      0.0|[0.09,6.0,254.0,4...|[-1.0141132719151...|[0.26617564876634...|       1.0|\n",
            "|              0.09|           0.78|             7|                 290|                 4|            0|   1|                    0| management|   low|     9.0|      0.0|[0.09,7.0,290.0,4...|[-0.7476154772494...|[0.32134109823457...|       1.0|\n",
            "|              0.09|            0.8|             6|                 298|                 4|            0|   1|                    0|    support|medium|     2.0|      1.0|[0.09,6.0,298.0,4...|[-0.5379291763935...|[0.36866943996868...|       1.0|\n",
            "+------------------+---------------+--------------+--------------------+------------------+-------------+----+---------------------+-----------+------+--------+---------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "eval=BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\",labelCol=\"left\")"
      ],
      "metadata": {
        "id": "XBxw21Z8WlCv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The final result or accuracy\n",
        "eval.evaluate(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ9coOcb-uOe",
        "outputId": "814c7ead-9dda-47f1-a053-68c8cf407127"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8132792648006996"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}